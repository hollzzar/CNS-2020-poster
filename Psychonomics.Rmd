---
title: Auditory comprehension of double versus single modal constructions in Mainstream American English listeners
poster_height: "36in"
poster_width: "48in"
font_family: Avenir
titletext_fontfamily: Avenir
primary_colour: "#001E44"
secondary_colour: "#016c5920"
accent_colour: "#d7d8db"
author:
  - name: Holly A. Zaharchuk
  - name: Adrianna Shevlin
  - name: Janet G. van Hell
affiliation:
  - address: Department of Psychology \& Center for Language Science, The Pennsylvania State University
column_numbers: 3
logoright_name: "Logo_PSU_white.png"
titlebox_borderwidth: "0.5cm"
sectitle_borderwidth: "1mm"
titlebox_bordercol: "#001E44"
author_textcol: "#FFFFFF"
sectitle_textsize: "45pt"
sectitle2_textsize: "40pt"
body_textsize: "30pt"
sectitle_boxshape: "3mm 0mm"
link_col: "#016c59"
columnline_style: solid
columnline_col: "#d7d8db"
columnline_width: "2mm"
output: 
  posterdown::posterdown_html:
    self_contained: false
bibliography: DoubleModals.bib
link-citations: no
csl: apa.csl
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
#R setup
chooseCRANmirror(graphics=FALSE, ind=1)
knitr::opts_chunk$set(warning=FALSE, message=FALSE)

#Load global variables
my_dir <- "/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/r_scripts"

#Load ERP plots
n <- "MAE"
source(paste(my_dir,"DM_plots.R",sep="/"), local=TRUE)

#Load attitude, background, SUSE variables, dialect, and judgment data
n <- "Behavior"
code_geo <- FALSE
new_image <- FALSE
source(paste(my_dir,"DM_attitudes_survey.R",sep="/"), local=TRUE)

#Restrict behavioral data to correct group
summary_MAE <- summary_back %>%
  dplyr::filter(ID %notin% SUSE_id$ID & ID %notin% "214")

#Create variables for graphs
scale_mean_5 <- mean(c(1,5))
scale_mean_4 <- mean(c(1,4))
text_size <- 12
theme_specs <- list(theme(text=element_text(family="Avenir"),
                          axis.title.x=element_blank(),
                          axis.ticks.x=element_blank(),
                          strip.background=element_blank(),
                          legend.key.size=unit(0.4, "cm"),
                          plot.title=element_text(size=text_size),
                          axis.title.y=element_text(size=text_size*0.75)))
```

# Background

### How do listeners process dialectal variation?

- Dialectal (regional, social, or ethnocultural) variation is inherent to language
- Theories of language processing are limited in their explanatory power of everyday speech without including variation
- Neurocognitive studies of dialect tend to focus on phonological (acoustic) or lexical (word-based) rather than syntactic (structural) variation
- Syntactic processing research with EEG typically relies written stimuli containing grammatical violations or ambiguities
- **Double modals**: indirectness or hedging <font size=5>[@hasty2012; @mishoe1994]</font>

# Stimuli

```{r stims, fig.align='center', echo=FALSE, out.width='100%'}
#Sentence strings
critical_dm_ex <- "\"She thinks she *might **should*** ask the professor for an extension.\""
critical_sm_ex <- "\"She thinks she ***should*** ask the professor for an extension.\""
critical_un_ex <- "\"She thinks she *could **should*** ask the professor for an extension.\""
critical_context <- "\"Kaitlyn is having a hard time with her essay.\""
filler_context <- "\"Kaitlyn waits for the bus every morning to go to work.\""
filler_ex <- "\"She said *the that* bus is usually late.\""
dm_predict <- "(N400-)P600"
sm_predict <- "Baseline"
un_predict <- "Not applicable"
fill_predict <- "Not analyzed"
off_predict <- "Pattern together"

#Stimulus table
headers <- c("Condition","Context sentence","Type","Experimental sentence","ERP prediction","Offline prediction")
critical_dm <- c("Critical",critical_context,"Attested double modal",critical_dm_ex,dm_predict,off_predict)
critical_sm <- c("Critical",critical_context,"Standard single modal",critical_sm_ex,sm_predict,sm_predict)
critical_un <- c("Critical",critical_context,"Unattested double modal",critical_un_ex,un_predict,off_predict)
filler <- c("Filler",filler_context,"",filler_ex,fill_predict,un_predict)
stim_table <- rbind(critical_sm, critical_dm, critical_un, filler)
rownames(stim_table) <- NULL
colnames(stim_table) <- headers

#Knit table
knitr::kable(stim_table) %>%
  kableExtra::kable_styling(font_size=35) %>%
  collapse_rows(columns = 1:6, valign = "middle") %>%
  row_spec(4, extra_css="border-top: 5px solid #d7d8db; border-bottom: 5px solid #d7d8db") %>%
  row_spec(3, extra_css="border-top: 5px solid #d7d8db") %>%
  footnote(general="ERP time-locked to second modal (could or should) in double modal sentences to compare to standard single modal",
           general_title="")
```

# Participants

```{r participants, fig.align='center', echo=FALSE, out.width='100%'}
#Participant table
cutoff <- "Exposure and familiarity"
cutoff_SUSE <- "\u2265 either scale mean"
cutoff_MAE <- "< both scale means"

headers <- c("Group", cutoff, "Stage", "Results presented", "Total", "Geography", "ERP", "Offline")
MAE_line <- c("MAE", cutoff_MAE, "Complete", "All", "32", "30", "27", "29")
SUSE_line <- c("SUSE", cutoff_SUSE, "Ongoing", "Geography", "10", "9", "", "")
stim_table <- rbind(MAE_line, SUSE_line)
rownames(stim_table) <- NULL
colnames(stim_table) <- headers

#Knit table
knitr::kable(stim_table) %>%
  kableExtra::kable_styling(font_size=35) %>%
  row_spec(1, background=paste0(sm_shade,"20")) %>%
  row_spec(2, background=paste0(dm_shade,"20"))
```

<hr style="height:10px; visibility:hidden;" />

```{r location, out.width='100%', echo=FALSE, dpi=300, fig.align='center'}
library(magick)
#Load map image and trim white space
dialect_map <- image_read("/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/poster/Psychonomics/dialect_map_caption.png")
dialect_map <- image_trim(dialect_map)
dialect_map
```

<hr style="height:10px; visibility:hidden;" />

## Mainstream American English listeners are sensitive to syntactic variation at both structure-building <br>(early AN) and integration (P600) levels of processing

```{r erp, fig.align='center', out.width='100%', echo=FALSE, dpi=300}
library(patchwork)
(buffer_plot / lf_plot / lp_plot / theme_plot) + plot_layout(heights = c(1,2,2,1)) | 
  (fz_plot / cz_plot / pz_plot) | 
  (buffer_plot / rf_plot / rp_plot / legend_plot) + plot_layout(heights = c(1,2,2,1))
```

<hr style="height:10px; visibility:hidden;" />

# Offline tasks

<hr style="height:10px; visibility:hidden;" />

```{r exposure, echo=FALSE, fig.height=3.1, out.width='100%', fig.align='left', dpi=300}
#Create subset of dataframe and set factor levels
exposure <- summary_MAE %>%
  select(ID, MC_mean, say_mean, hear_mean, south_only, hear_only, say_only) %>%
  gather(type, rating, -ID) %>%
  mutate(group=ifelse(str_detect(type,"only"),"Southern features","Double modals"),
         type=ifelse(str_detect(type,"hear"),"Comprehension",
                     ifelse(str_detect(type,"say"),"Production","Overall")),
         type=factor(type,
                     levels=c("Overall","Comprehension","Production"),
                     labels=c("Overall exposure","Comprehension","Production")))

#Create table with confidence intervals
library(Rmisc)
exposure_error <- summarySE(exposure, measurevar="rating", groupvars=c("group","type"))

#Create plot
ggplot(exposure_error, aes(group, rating, fill=group)) +
  geom_bar(position="dodge", stat="identity") +
  geom_errorbar(aes(ymin=rating-ci, ymax=rating+ci), width=0.1) +
  facet_wrap(~type, strip.position="bottom") +
  scale_y_continuous(expand=c(0,0), limits=c(0,3), breaks=c(1,2,3)) +
  coord_cartesian(ylim=c(1,3.01)) +
  scale_x_discrete(expand=c(0,0)) +
  geom_hline(aes(yintercept=scale_mean_5,linetype="Scale mean")) +
  theme_classic() +
  scale_fill_manual(values=c(dm_shade,paste0(dm_shade,"50")),
                    name="Exposure type") +
  labs(title="Exposure to double modals compared to other Southern dialect features") +
  scale_linetype_manual(name="Scale type",
                        values="dashed",
                        labels="Scale mean") +
  labs(caption="Southern dialect exposure means do not include exposure to double modals") +
  guides(fill=guide_legend(order=1),
         linetype=guide_legend(order=2)) +
  theme_specs +
    theme(axis.text.x=element_blank()) +
  ylab("Mean rating (by participant)")
```

```{r accpt, echo=FALSE, fig.height=3.1, out.width='100%', fig.align='left', dpi=300}
#Create subset of dataframe and set factor levels
MAE_mean_multi <- summary_MAE %>%
  select(ID, contains("double"), contains("incorrect"), contains("standard")) %>%
  gather(type, rating, -ID) %>%
  separate(type,c("modal","measure"),sep="_",remove=FALSE) %>%
  mutate(modal=factor(modal,
                      levels=c("standard","double","incorrect"),
                      labels=c("Standard single modal", "Attested double modal", "Unattested double modal")),
         measure=factor(measure,
                        levels=c("acceptable","understand","familiar"),
                        labels=c("Acceptability","Intelligibility","Familiarity"))) %>%
  drop_na()

#Create table with confidence intervals
library(Rmisc)
MAE_multi_error <- summarySE(MAE_mean_multi, measurevar="rating", groupvars=c("modal","measure"))
MAE_multi_error <- MAE_multi_error %>% 
  mutate(scale=rep(c(scale_mean_5,scale_mean_5,scale_mean_4),3),
         max=rep(c(5,5,4),3))

#Create plot
ggplot(MAE_multi_error, aes(modal, rating, fill=modal)) +
  geom_bar(position="dodge", stat="identity") +
  geom_errorbar(aes(ymin=rating-ci, ymax=rating+ci), width=0.1) +
  scale_y_continuous(expand=c(0,0),limits=c(0,5)) +
  coord_cartesian(ylim=c(1,5.01)) +
  scale_x_discrete(expand=c(0,0)) +
  theme_classic() +
  facet_wrap(~measure, strip.position="bottom") +
  scale_fill_manual(values=c(sm_shade,dm_shade,psu_grey),
                    name="Modal type") +
  geom_hline(aes(yintercept=scale,linetype="Scale mean")) +
  geom_hline(aes(yintercept=max,linetype="Scale maximum")) +
  scale_linetype_manual(name="Scale type",
                        values=c("solid","dashed"),
                        labels=c("Scale maximum","Scale mean")) +
  labs(title="Ratings of experimental sentence stimuli") +
  theme_specs +
  theme(axis.text.x=element_blank()) +
  ylab("Mean rating (by participant)")
```

<font size=5>All error bars represent 95% confidence intervals</font>
<hr style="height:10px; visibility:hidden;" />

```{r matrix, echo=FALSE, fig.align='center', dpi=300}
#Pull values for correlation matrix
south_dat <- summary_MAE %>% 
  select(double_acceptable, double_familiar, double_understand, South, MC_mean, south_only)

#Create correlation matrix and separate coefficients from p values
south_matrix <- rcorr(as.matrix(south_dat),type="pearson")
south_r <- as.data.frame(south_matrix$r)
south_p <- as.data.frame(south_matrix$P)
cor_vals_row <- colnames(south_r)
cor_vals_col <- colnames(south_r)
cor_len <- length(cor_vals_row)

#Rename rows and columns in lists
for (i in 1:cor_len) {
  
  #Edit lists of names
  cor_vals_row[i] <- paste(cor_vals_row[i], "_row", sep="")
  cor_vals_col[i] <- paste(cor_vals_col[i], "_col", sep="")
  
}

#Rename columns
colnames(south_r) <- cor_vals_col
colnames(south_p) <- cor_vals_col

#Change row and column names in order to gather
south_r <- tibble::rowid_to_column(south_r, "row_key") %>%
  mutate(row_key=cor_vals_row)
south_p <- tibble::rowid_to_column(south_p, "row_key") %>%
  mutate(row_key=cor_vals_row)

#Gather into long format
south_r <- south_r %>%
  gather(col_key, coef, -row_key)
south_p <- south_p %>%
  gather(col_key, p_val, -row_key)

#Combine coeffients and p values
south_matrix <- full_join(south_r, south_p) %>%
  mutate(p_val=replace_na(p_val,1))

#Create columns for final table
south_matrix <- south_matrix %>%
  mutate(p_label=ifelse(p_val <= 0.001, "***",
                        ifelse(p_val <= 0.01, "**",
                               ifelse(p_val <= 0.05, "*", ""))),
         coef_label=as.character(format(coef,digits=1,nsmall=1)),
         table_val=paste(coef_label, p_label, sep=""),
         table_val=ifelse(table_val==" 1.00","1",table_val))

#Reformat table for printing
south_table <- south_matrix %>%
  select(row_key, col_key, table_val) %>%
  spread(col_key, table_val) %>%
  select(row_key, double_acceptable_col, double_familiar_col, double_understand_col, 
         MC_mean_col, south_only_col, South_col)

#Rename rows and columns
var_names <- c("Acceptability", "Familiarity", "Intelligibility", "Exposure (DM)", 
               "Exposure (SUSE)", "Culture")
colnames(south_table) <- c("Variables", var_names)
south_table <- south_table %>%
  mutate(Variables=var_names)

#Remove unnecessary variables
rm(var_names, south_matrix, south_p, south_r, cor_vals_row, cor_vals_col, cor_len, south_dat)

#Create table
knitr::kable(south_table) %>%
  kableExtra::kable_styling(full_width=TRUE, font_size=30) %>%
  row_spec(6, extra_css="border-bottom: 5px solid #d7d8db") %>%
  add_header_above(header=c("Pairwise Pearson correlation matrix"=7), align="l") %>%
  footnote(general="All pairwise correlations with centro-parietal P600 amplitude and language attitudes n.s. at *p* < .05 level",
           general_title="", footnote_as_chunk=TRUE)
```

<hr style="height:10px; visibility:hidden;" />

```{r paraphrase, echo=FALSE, fig.height=3.1, out.width='100%', fig.align='left', dpi=300}
#Create scale variables
sm_scale <- 1
dm_scale <- 2

#Get paraphrase rates
paraphrase_labels <- paraphrase %>%
  dplyr::filter(ID %notin% SUSE_id$ID & ID %notin% "214")
paraphrase_total <- nrow(paraphrase_labels)
paraphrase_labels <- paraphrase_labels %>%
  dplyr::filter(response_score > 0)
paraphrase_actual <- nrow(paraphrase_labels)
paraphrase_rate <- paraphrase_actual/paraphrase_total

#Create subset of dataframe and set factor levels
MAE_paraphrase <- paraphrase %>%
  dplyr::filter(ID %notin% SUSE_id$ID & ID %notin% "214" & response_score > 0) %>%
  select(ID, modal, condition, epist_score, root_score, response_score) %>%
  gather(key, score, -c(ID, modal, condition)) %>%
  mutate(modal=factor(modal,
                       levels=c("could","should"),
                       labels=c("Could", "Should")),
         condition=factor(condition,
                      levels=c("standard","double","incorrect"),
                      labels=c("Standard single modal", "Attested double modal", "Unattested double modal")),
         key=factor(key,
                    levels=c("response_score", "epist_score", "root_score"),
                    labels=c("Overall meaning", "Epistemic meaning", "Root meaning")))

#Create table with confidence intervals
library(Rmisc)

MAE_paraphrase_error <- summarySE(MAE_paraphrase, measurevar="score", groupvars=c("modal","condition","key"))
MAE_paraphrase_error <- MAE_paraphrase_error %>%
  arrange(key) %>%
  mutate(line_1=c(rep(dm_scale,6), rep(NA,12)),
         line_2=c(rep(sm_scale,6), rep(NA,12)),
         line_3=c(rep(NA,6), rep(sm_scale,12)),
         y_max=c(rep(2.01,6), rep(1.005,12)),
         y_min=c(rep(0,18)),
         proportion=paste0(as.character(round((N/paraphrase_actual)*100,1)),"%"))

#Create plot
ggplot(MAE_paraphrase_error, aes(modal, score,
                                 ymin=score-ci, ymax=score+ci,
                                 fill=condition)) +
  geom_bar(position="dodge", stat="identity") +
  geom_errorbar(width=0.2, position=position_dodge(width=0.9)) +
  scale_y_continuous(expand=c(0,0), breaks=pretty_breaks()) +
  scale_x_discrete(expand=c(0,0)) +
  theme_classic() +
  facet_wrap(~key, strip.position="bottom", scales="free_y") +
  geom_hline(aes(yintercept=line_3,linetype="Standard single modals")) +
  geom_hline(aes(yintercept=line_1,linetype="Attested double modals")) +
  geom_hline(aes(yintercept=line_2,linetype="Individual modals")) +
  geom_blank(aes(y=y_min)) +
  geom_blank(aes(y=y_max)) +
  scale_fill_manual(values=c(sm_shade,dm_shade,psu_grey),
                    name="Modal type") +
  scale_linetype_manual(name="Score expectation",
                        values=c("solid","dashed","dotted"),
                        labels=c("Attested double modals",
                                 "Standard single modals",
                                 "Individual modals")) +
  labs(title="Paraphrases of experimental sentence stimuli",
       caption="Epistemic modals express subjective impressions of truth or likelihood (might) \nRoot modals express possibility, permission, necessity, or obligation (could/should)") +
  theme_specs +
  guides(fill=guide_legend(order=1),
         linetype=guide_legend(order=2)) +
  ylab("Mean paraphrase score (across participants)")
  # geom_text(aes(label=proportion), position=position_dodge(width=0.9))
```

# Results

- Biphasic response to syntactic variation transitions from anterior negativity to centro-parietal positivity
    - Early anterior negativity (early AN) suggests **automatic detection** of non-standard language
    - Robust P600 effect reflects **syntactic reanalysis** for double modal sentences
- Likelihood of hearing attested double modals significantly **higher** than likelihood of saying them, but significantly **lower** than likelihood of hearing other Southern dialect features (e.g., negative concord)
- Familiarity with attested double modals significantly **higher** than unattested
- Attested double modals, especially *might could*, significantly **easier** to paraphrase than unattested double modals

# Conclusion

- Combining neurocognitive and linguistic methods reveals dynamic interactions among language exposure, use, and processing
- MAE listeners require additional neural resources during online processing of double modals but show successful integration offline
- SUSE listeners are expected to show enhanced processing for attested double modals compared to standard single modals
- **Future direction**: studying SUSE speakers in their local communities with *The Brain Bus* (mobile EEG system)

# References and acknowledgements

<font size=3><div id="refs"></div></font>

<img style="padding: 0 15px; float:left;" src="Logo_CLA_blue.png" width=30% height=30%> <div style="text-align: right"><font size=6>Holly Zaharchuk: hzaharchuk@psu.edu</font></div> <div style="text-align: right"><font size=6>University Graduate Fellow (UGF)</font></div>