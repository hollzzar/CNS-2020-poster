rename(ID="Participant number")
background <- background %>%
select("Participant number":"How would you rate your current proficiency in this language?") %>%
rename(ID="Participant number")
#Remove participants
attitude <- attitude %>% dplyr::filter(ID %notin% non_mae & str_detect(ID, "X", negate=TRUE))
background <- background %>%
dplyr::filter(ID %notin% non_mae & str_detect(ID, "X", negate=TRUE)) %>%
mutate(erp_code=1,
erp_code=replace(erp_code,str_detect(ID,erp_reject),0)) %>%
mutate_at(ID, funs(as.character))
#Read in attitudes and background data
attitude <- read.csv(att, header=TRUE, check.names=FALSE, na.strings=c("","NA","N/A"))
background <- read.csv(back, header=TRUE, check.names=FALSE, na.strings=c("","NA","N/A")) %>%
mutate_at(ID, funs(as.character))
#Read in attitudes and background data
attitude <- read.csv(att, header=TRUE, check.names=FALSE, na.strings=c("","NA","N/A"))
background <- read.csv(back, header=TRUE, check.names=FALSE, na.strings=c("","NA","N/A"))
#Remove timestamp columns
attitude <- attitude %>%
select("Participant number":"I correct people when they make grammatical errors.") %>%
rename(ID="Participant number") %>%
mutate_at(ID, funs(as.character))
#Remove timestamp columns
attitude <- attitude %>%
select("Participant number":"I correct people when they make grammatical errors.") %>%
rename(ID="Participant number") %>%
mutate_at("ID", funs(as.character))
#Read in attitudes and background data
attitude <- read.csv(att, header=TRUE, check.names=FALSE, na.strings=c("","NA","N/A"))
background <- read.csv(back, header=TRUE, check.names=FALSE, na.strings=c("","NA","N/A"))
#Remove timestamp columns
attitude <- attitude %>%
select("Participant number":"I correct people when they make grammatical errors.") %>%
rename(ID="Participant number") %>%
mutate_at("ID", funs(as.character))
background <- background %>%
select("Participant number":"How would you rate your current proficiency in this language?") %>%
rename(ID="Participant number") %>%
mutate_at("ID", funs(as.character))
#Remove participants
attitude <- attitude %>% dplyr::filter(ID %notin% non_mae & str_detect(ID, "X", negate=TRUE))
background <- background %>%
dplyr::filter(ID %notin% non_mae & str_detect(ID, "X", negate=TRUE)) %>%
mutate(erp_code=1,
erp_code=replace(erp_code,str_detect(ID,erp_reject),0))
#Create new dataframe for clean data
summary_back <- background %>% select(ID)
#Pull mood data
mood <- background[grep("mood|today",colnames(background),ignore.case=TRUE)] %>%
mutate(ID=background$ID)
colnames(mood) <- c("good_1","bad_1","good_2","good_3","bad_2","bad_3","ID")
#Reverse-code ratings for bad mood questions and calculate average mood
mood <- mood %>%
mutate(rev_1=dplyr::recode(bad_1,"1"=5,"2"=4,"4"=2,"5"=1,"3"=3),
rev_2=dplyr::recode(bad_2,"1"=5,"2"=4,"4"=2,"5"=1,"3"=3),
rev_3=dplyr::recode(bad_3,"1"=5,"2"=4,"4"=2,"5"=1,"3"=3)) %>%
rowwise() %>%
mutate(mood_mean=mean(c(good_1,good_2,good_3,rev_1,rev_2,rev_3))) %>%
ungroup()
#Add average mood to background dataset
summary_back <- mood %>% select(ID, mood_mean) %>%
mutate_all(funs(as.character)) %>%
right_join(summary_back, by="ID")
#Calculate handedness scores
handed <- background %>%
select(ID, "Writing":"Opening a box (lid)") %>%
mutate_all(funs(as.character)) %>%
gather(category, response, -ID) %>%
filter(response %notin% "") %>%
mutate(hand=dplyr::recode(response,
"Always right"=5,
"Right"=4,
"No preference"=3,
"Left"=2,
"Always left"=1))
handed_score <- handed %>% group_by(ID) %>% summarise(handed=mean(hand))
#Add handedness score to background dataset
summary_back <- right_join(handed_score, summary_back, by="ID")
#Reshape geography data
geo <- background %>%
select(ID, "Where were you born?":"Where did your mother grow up?", "Where did your father grow up?") %>%
mutate_all(funs(as.character)) %>%
gather(category, response, -ID) %>%
mutate(cat_code="not coded",
cat_code=replace(cat_code,str_detect(category,"born"),"birth"),
cat_code=replace(cat_code,str_detect(category,"childhood"),"childhood"),
cat_code=replace(cat_code,str_detect(category,"high school"),"adolescence"),
cat_code=replace(cat_code,str_detect(category,"mother"),"mother"),
cat_code=replace(cat_code,str_detect(category,"father"),"father"))
#Display and recode missing/incomplete data
geo <- geo %>%
mutate(response=replace(response,response=="Virginia and Iowa","unknown,multiple"),
response=replace(response,is.na(response),"unknown,unknown"),
response=replace(response,response=="Canada","unknown,Canada"),
response=replace(response,str_detect(response,"Dominica"),"unknown,Dominican Republic"),
response=replace(response,str_detect(response,"Puerto"),"unknown,Puerto Rico")) %>%
separate(response, c("town", "state"), sep=",", remove=FALSE, extra="merge")
#Trim white space
geo$state <- trimws(geo$state, which="both")
#Code geography data
geo <- geo %>%
mutate(state_recode=state,
state_recode=replace(state_recode,state=="PA","Pennsylvania"),
state_recode=replace(state_recode,state=="Pa","Pennsylvania"),
state_recode=replace(state_recode,state=="NY","New York"))
#Reshape data
geo_reshape <- geo %>%
select(ID, cat_code, town, state_recode) %>%
group_by(ID) %>%
unite(place, town, state_recode, sep=", ") %>%
spread(cat_code, place)
#Add geography to background dataset
summary_back <- geo_reshape %>% right_join(summary_back, by="ID")
#Check race, ethnicity, and gender data
background %>% filter(is.na(Race) | is.na(Ethnicity) | is.na(Gender))
#Recode missing data
summary_back <- background %>%
select(ID, Race, Ethnicity, Gender) %>%
replace_na(list(rep("unknown",3))) %>%
right_join(summary_back, by="ID")
mood %>% select(ID, mood_mean) %>%
# mutate_all(funs(as.character)) %>%
right_join(summary_back, by="ID")
rm(attitude, background, summary_back, mood, handed, handed_score, geo, geo_reshape)
#Read in attitudes and background data
attitude <- read.csv(att, header=TRUE, check.names=FALSE, na.strings=c("","NA","N/A"))
background <- read.csv(back, header=TRUE, check.names=FALSE, na.strings=c("","NA","N/A"))
#Remove timestamp columns
attitude <- attitude %>%
select("Participant number":"I correct people when they make grammatical errors.") %>%
rename(ID="Participant number") %>%
mutate_at("ID", funs(as.character))
background <- background %>%
select("Participant number":"How would you rate your current proficiency in this language?") %>%
rename(ID="Participant number") %>%
mutate_at("ID", funs(as.character))
#Remove participants
attitude <- attitude %>% dplyr::filter(ID %notin% non_mae & str_detect(ID, "X", negate=TRUE))
background <- background %>%
dplyr::filter(ID %notin% non_mae & str_detect(ID, "X", negate=TRUE)) %>%
mutate(erp_code=1,
erp_code=replace(erp_code,str_detect(ID,erp_reject),0))
knitr::opts_chunk$set(echo = TRUE)
# handy package manager that installs and loads packages used in this document
if (!("pacman" %in% installed.packages()[,"Package"])) { install.packages("pacman") }
pacman::p_load(tidyverse, psych, GGally, Rmisc, interactions) # install (if needed) and load packages
# Load data and convert sex and education to factors
source(paste0(params$path_2_scripts, "load_sat_act.R"))
# Print the first five rows in the dataset
head(sat.act, n=5)
# Examine the structure of the dataset
str(sat.act)
# Looking at a histogram for a single variable
ggplot(sat.act, aes(ACT)) +
geom_histogram(bins = 20) # you can change the bin value to best fit your data
# Looking at histograms for all variables ggplot option
ggplot(sat.act %>% dplyr::select(-sex, -education) %>% # removing dichotomous variables
gather(), aes(value)) + # grouping for visualization
geom_histogram(bins = 20) +
facet_wrap(~key, scales = "free_x") # free_x allows for differing x-axes
ggplot(sat.act %>% dplyr::select(-sex, -education) %>% # removing dichotomous variables
gather(), aes(value)) + # grouping for visualization
geom_histogram(bins = 20)
sat.act %>% filter(is.na(ACT))
sat.act %>% filter(is.na(age))
sat.act %>% filter(is.na(SATQ))
# Looking at histograms for all variables ggplot option
ggplot(sat.act %>% dplyr::select(-sex, -education) %>% # removing dichotomous variables
gather(), aes(value)) + # grouping for visualization
geom_histogram(bins = 20) +
facet_wrap(~key, scales = "free_x") # free_x allows for differing x-axes
# Looking at a histogram for a single variable
ggplot(sat.act, aes(ACT)) +
geom_histogram(bins = 20) # you can change the bin value to best fit your data
# Looking at histograms for all variables ggplot option
ggplot(sat.act %>% dplyr::select(-sex, -education) %>% # removing dichotomous variables
gather(), aes(value)) + # grouping for visualization
geom_histogram(bins = 20) +
facet_wrap(~key, scales = "free_x") # free_x allows for differing x-axes
sat.act %>% filter(is.na(SATV))
# Simple descriptive scatter plot
ggplot(sat.act, aes(age, ACT)) +
# geom_ allows you to select the type of object you would like to comprise the graph
geom_point() +
# You can add axis labels and titles
ylab("Score") +
xlab("Age") +
ggtitle("ACT scores by age") +
# You can set different themes to alter the general appearance of your graphs (more description in the aesthetics section)
theme_classic()
# Descriptive scatterplot with additional element
scatter <- ggplot(sat.act, aes(age, ACT, color=education)) +
geom_point() +
ylab("Score") +
xlab("Age") +
labs(color="Education level") +
ggtitle("ACT scores by age and education level") +
theme_classic()
# If you have saved your graph into an object, as above, you can call the object to view
scatter
scatter <- scatter + geom_smooth(method="lm", se=FALSE, color="gray50")
scatter
ggpairs(sat.act %>% na.omit(), progress=FALSE,
lower = list(combo = wrap("facethist", bins=6)))
# Bar graph with counts
ggplot(sat.act, aes(education)) +
geom_bar() +
ylab("Number of subjects") +
xlab("Education level") +
ggtitle("Count of subjects at each education level") +
theme_classic()
# Bar graph with means
ggplot(sat.act, aes(education, ACT)) +
geom_bar(stat="summary", fun.y="mean") +
ylab("Average score") +
xlab("Education level") +
ggtitle("Average ACT scores at each education level") +
theme_classic()
# creating a summary of the variables of interest to extract error bars
sat.act.sum <- summarySE(sat.act, measurevar="ACT", groupvars=c("education"))
sat.act.sum
# we use the summary we created to plot
ggplot(sat.act.sum, aes(education, ACT)) +
geom_bar(stat="summary", fun.y="mean") +
geom_errorbar(aes(ymin=ACT-se, ymax=ACT+se),
width=.2, position=position_dodge(.9))
# we use the summary we created to plot
ggplot(sat.act.sum, aes(education, ACT)) +
geom_bar(stat="summary", fun.y="mean") +
geom_errorbar(aes(ymin=ACT-se, ymax=ACT+se),
width=.2, position=position_dodge(.9)) +
theme_classic()
# we use the summary we created to plot
ggplot(sat.act.sum, aes(education, ACT)) +
geom_bar(stat="summary", fun.y="mean") +
ylab("Average score") +
xlab("Education level") +
ggtitle("Average ACT scores at each education level") +
geom_errorbar(aes(ymin=ACT-se, ymax=ACT+se),
width=.2, position=position_dodge(.9)) +
theme_classic()
sat.act.sum
bar <- ggplot(sat.act, aes(education, ACT)) +
geom_bar(stat="summary", fun.y="mean") +
ylab("Average score") +
xlab("Education level") +
ggtitle("Average ACT scores at each education level") +
theme_classic()
bar
# we use the summary we created to plot
bar + geom_errorbar(aes(ymin=ACT-se, ymax=ACT+se),
width=.2, position=position_dodge(.9)) +
theme_classic()
# we use the summary we created to plot
ggplot(sat.act.sum, aes(education, ACT)) +
geom_bar(stat="summary", fun.y="mean") +
ylab("Average score") +
xlab("Education level") +
ggtitle("Average ACT scores at each education level") +
geom_errorbar(aes(ymin=ACT-se, ymax=ACT+se),
width=.2, position=position_dodge(.9)) +
theme_classic()
x <- geo %>%
select(ID, cat_code, town, state_recode)
#Reshape geography data
geo <- background %>%
select(ID, "Where were you born?":"Where did your mother grow up?", "Where did your father grow up?") %>%
mutate_all(funs(as.character)) %>%
gather(category, response, -ID) %>%
mutate(cat_code="not coded",
cat_code=replace(cat_code,str_detect(category,"born"),"birth"),
cat_code=replace(cat_code,str_detect(category,"childhood"),"childhood"),
cat_code=replace(cat_code,str_detect(category,"high school"),"adolescence"),
cat_code=replace(cat_code,str_detect(category,"mother"),"mother"),
cat_code=replace(cat_code,str_detect(category,"father"),"father"))
#Display and recode missing/incomplete data
geo <- geo %>%
mutate(response=replace(response,response=="Virginia and Iowa","unknown,multiple"),
response=replace(response,is.na(response),"unknown,unknown"),
response=replace(response,response=="Canada","unknown,Canada"),
response=replace(response,str_detect(response,"Dominica"),"unknown,Dominican Republic"),
response=replace(response,str_detect(response,"Puerto"),"unknown,Puerto Rico")) %>%
separate(response, c("town", "state"), sep=",", remove=FALSE, extra="merge")
#Trim white space
geo$state <- trimws(geo$state, which="both")
#Code geography data
geo <- geo %>%
mutate(state_recode=state,
state_recode=replace(state_recode,state=="PA","Pennsylvania"),
state_recode=replace(state_recode,state=="Pa","Pennsylvania"),
state_recode=replace(state_recode,state=="NY","New York"))
View(geo)
#Reshape geography data
geo <- background %>%
select(ID, "Where were you born?":"Where did your mother grow up?", "Where did your father grow up?") %>%
replace_na("unknown,unknown")
#Reshape geography data
geo <- background %>%
select(ID, "Where were you born?":"Where did your mother grow up?", "Where did your father grow up?") %>%
mutate_all(funs(as.character)) %>%
gather(category, response, -ID) %>%
mutate(cat_code="not coded",
cat_code=replace(cat_code,str_detect(category,"born"),"birth"),
cat_code=replace(cat_code,str_detect(category,"childhood"),"childhood"),
cat_code=replace(cat_code,str_detect(category,"high school"),"adolescence"),
cat_code=replace(cat_code,str_detect(category,"mother"),"mother"),
cat_code=replace(cat_code,str_detect(category,"father"),"father"))
geo <- geo %>%
mutate(response=replace(response,response=="Virginia and Iowa","unknown,multiple"),
response=replace(response,is.na(response),"unknown,unknown"),
response=replace(response,response=="Canada","unknown,Canada"),
response=replace(response,str_detect(response,"Dominica"),"unknown,Dominican Republic"),
response=replace(response,str_detect(response,"Puerto"),"unknown,Puerto Rico")) %>%
separate(response, c("town", "state"), sep=",", remove=FALSE, extra="merge")
#Trim white space
geo$state <- trimws(geo$state, which="both")
#Code geography data
geo <- geo %>%
mutate(state_recode=state,
state_recode=replace(state_recode,state=="PA","Pennsylvania"),
state_recode=replace(state_recode,state=="Pa","Pennsylvania"),
state_recode=replace(state_recode,state=="NY","New York"))
#Reshape data
geo_reshape <- geo %>%
select(ID, cat_code, town, state_recode) %>%
group_by(ID) %>%
unite(place, town, state_recode, sep=", ") %>%
spread(cat_code, place)
View(geo)
rm(summary_back, mood, handed, handed_score, geo, geo_reshape)
View(attitude)
View(background)
View(attitude)
#Create new dataframe for clean data
summary_back <- background %>% select(ID)
background %>% filter(is.na(everything()))
#Check race, ethnicity, and gender data
background %>% filter(is.na(Race) | is.na(Ethnicity) | is.na(Gender))
background %>% filter_all(any_vars(is.na()))
background %>% filter_all(is.na(any_vars()))
background %>% filter_all(all_vars(), is.na())
background %>% filter_all(all_vars(is.na()))
background %>% filter_all(all_vars(is.na(.)))
background %>% filter_all(all_vars(is.na(.)))
background %>% filter_all(any_vars(is.na(.)))
background %>% filter_all(any_vars(is.na(.)))
background %>% filter_at(any_vars(is.na(.)))
#Recode missing data
summary_back <-
x <- background %>%
select(ID, Race, Ethnicity, Gender) %>%
replace(is.na(.), "unknown")
x <- background %>%
select(ID, Race, Ethnicity, Gender) %>%
replace(is.na(.), "unknown")
View(x)
rm(x)
View(background)
x <- background %>%
select(Race, Ethnicity, Gender) %>%
replace(is.na(.), "unknown")
# Install packages
install.packages(c("SemNetDictionaries", "SemNetCleaner",
"SemNeT", "NetworkToolbox"))
# Load packages
library(SemNetDictionaries)
library(SemNetCleaner)
library(SemNeT)
library(NetworkToolbox)
# Documentation for `textcleaner` function
?textcleaner
# Run 'textcleaner'
clean <- textcleaner(data = open.animals[,-c(1:2)], miss = 99,
partBY = "row", dictionary = "animals")
rm(clean)
clean <- textcleaner(data = open.animals[,-c(1:2)], miss = 99,
partBY = "row", dictionary = "animals")
?loadNamespace
# Load packages
library(SemNetDictionaries)
library(SemNetCleaner)
library(SemNeT)
library(NetworkToolbox)
# Append 'animals.dictionary'
append.dictionary(animals.dictionary,
"tasselled wobbegong",
save.location = "choose")
?XQuartz
#R setup
chooseCRANmirror(graphics=FALSE, ind=1)
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
#Load global variables
my_dir <- "/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/r_scripts"
#Load ERP plots
n <- "MAE"
source(paste(my_dir,"DM_plots.R",sep="/"), local=TRUE)
#Load attitude, background, SUSE variables, dialect, and judgment data
n <- "Behavior"
code_geo <- FALSE
new_image <- FALSE
source(paste(my_dir,"DM_attitudes_survey.R",sep="/"), local=TRUE)
#Set directory back to poster
setwd("/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/poster/Psychonomics_html")
#Create scale variables
scale_mean_5 <- mean(c(1,5))
scale_mean_4 <- mean(c(1,4))
#Create subset of dataframe and set factor levels
MAE_mean_multi <- mean_multi %>%
dplyr::filter(ID %notin% SUSE_id$ID) %>%
gather(type, rating, -ID) %>%
separate(type,c("modal","measure"),sep="_",remove=FALSE) %>%
mutate(modal=factor(modal,
levels=c("standard","double","incorrect"),
labels=c("Standard single modal", "Attested double modal", "Unattested double modal")),
measure=factor(measure,
levels=c("acceptable","understand","familiar"),
labels=c("Acceptability","Intelligibility","Familiarity")))
#Create table with confidence intervals
library(Rmisc)
MAE_multi_error <- summarySE(MAE_mean_multi, measurevar="rating", groupvars=c("modal","measure"))
detach("package:Rmisc", unload=TRUE)
MAE_multi_error <- MAE_multi_error %>% mutate(scale=rep(c(scale_mean_5,scale_mean_5,scale_mean_4),3),
max=rep(c(5,5,4),3))
#Create plot
ggplot(MAE_multi_error, aes(modal, rating, fill=modal)) +
geom_bar(position="dodge", stat="identity") +
geom_errorbar(aes(ymin=rating-ci, ymax=rating+ci), width=0.1) +
scale_y_continuous(expand=c(0,0),limits=c(0,5)) +
coord_cartesian(ylim=c(1,5.01)) +
scale_x_discrete(expand=c(0,0)) +
theme_classic() +
facet_wrap(~measure, strip.position="bottom") +
scale_fill_manual(values=c(sm_shade,dm_shade,psu_grey),
name="Modal type") +
geom_hline(aes(yintercept=scale,linetype="Scale mean")) +
geom_hline(aes(yintercept=max,linetype="Scale maximum")) +
scale_linetype_manual(name="Scale type",
values=c("solid","dashed"),
labels=c("Scale maximum","Scale mean")) +
theme(text=element_text(family="Avenir"),
axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank(),
strip.background=element_blank()) +
ylab("Mean ratings")
#Create scale variables
scale_mean_5 <- mean(c(1,5))
scale_mean_4 <- mean(c(1,4))
#Create subset of dataframe and set factor levels
MAE_mean_multi <- mean_multi %>%
dplyr::filter(ID %notin% SUSE_id$ID) %>%
gather(type, rating, -ID) %>%
separate(type,c("modal","measure"),sep="_",remove=FALSE) %>%
mutate(modal=factor(modal,
levels=c("standard","double","incorrect"),
labels=c("Standard single modal", "Attested double modal", "Unattested double modal")),
measure=factor(measure,
levels=c("acceptable","understand","familiar"),
labels=c("Acceptability","Intelligibility","Familiarity")))
#Create table with confidence intervals
library(Rmisc)
MAE_multi_error <- summarySE(MAE_mean_multi, measurevar="rating", groupvars=c("modal","measure"))
detach("package:Rmisc", unload=TRUE)
MAE_multi_error <- MAE_multi_error %>% mutate(scale=rep(c(scale_mean_5,scale_mean_5,scale_mean_4),3),
max=rep(c(5,5,4),3))
#Create plot
ggplot(MAE_multi_error, aes(modal, rating, fill=modal)) +
geom_bar(position="dodge", stat="identity") +
geom_errorbar(aes(ymin=rating-ci, ymax=rating+ci), width=0.1) +
scale_y_continuous(expand=c(0,0),limits=c(0,5)) +
coord_cartesian(ylim=c(1,5.01)) +
scale_x_discrete(expand=c(0,0)) +
theme_classic() +
facet_wrap(~measure, strip.position="bottom") +
scale_fill_manual(values=c(sm_shade,dm_shade,psu_grey),
name="Modal type") +
geom_hline(aes(yintercept=scale,linetype="Scale mean")) +
geom_hline(aes(yintercept=max,linetype="Scale maximum")) +
scale_linetype_manual(name="Scale type",
values=c("solid","dashed"),
labels=c("Scale maximum","Scale mean")) +
theme(text=element_text(family="Avenir"),
axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank(),
strip.background=element_blank()) +
ylab("Mean ratings")
#R setup
chooseCRANmirror(graphics=FALSE, ind=1)
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
#Load global variables
my_dir <- "/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/r_scripts"
#Load ERP plots
n <- "MAE"
source(paste(my_dir,"DM_plots.R",sep="/"), local=TRUE)
#Load attitude, background, SUSE variables, dialect, and judgment data
n <- "Behavior"
code_geo <- FALSE
new_image <- FALSE
source(paste(my_dir,"DM_attitudes_survey.R",sep="/"), local=TRUE)
#Set directory back to poster
setwd("/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/poster/Psychonomics_html")
library(magick)
setwd("/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/poster/Psychonomics")
pagedown::chrome_print("file://localhost/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/poster/Psychonomics_poster/Psychonomics.html")
setwd("/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/poster/Psychonomics_poster")
pagedown::chrome_print("file://localhost/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/poster/Psychonomics_poster/Psychonomics.html")
setwd("/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/poster/Psychonomics_poster")
pagedown::chrome_print("file://localhost/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/poster/Psychonomics_poster/Psychonomics.html")
setwd("/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/poster/Psychonomics_poster")
pagedown::chrome_print("file://localhost/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/poster/Psychonomics_poster/Psychonomics.html")
