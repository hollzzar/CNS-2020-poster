geo$state <- trimws(geo$state, which="both")
#Code geography data
geo <- geo %>%
mutate(state_recode=state,
state_recode=replace(state_recode,state=="PA","Pennsylvania"),
state_recode=replace(state_recode,state=="Pa","Pennsylvania"),
state_recode=replace(state_recode,state=="NY","New York"))
View(geo)
#Reshape geography data
geo <- background %>%
select(ID, "Where were you born?":"Where did your mother grow up?", "Where did your father grow up?") %>%
replace_na("unknown,unknown")
#Reshape geography data
geo <- background %>%
select(ID, "Where were you born?":"Where did your mother grow up?", "Where did your father grow up?") %>%
mutate_all(funs(as.character)) %>%
gather(category, response, -ID) %>%
mutate(cat_code="not coded",
cat_code=replace(cat_code,str_detect(category,"born"),"birth"),
cat_code=replace(cat_code,str_detect(category,"childhood"),"childhood"),
cat_code=replace(cat_code,str_detect(category,"high school"),"adolescence"),
cat_code=replace(cat_code,str_detect(category,"mother"),"mother"),
cat_code=replace(cat_code,str_detect(category,"father"),"father"))
geo <- geo %>%
mutate(response=replace(response,response=="Virginia and Iowa","unknown,multiple"),
response=replace(response,is.na(response),"unknown,unknown"),
response=replace(response,response=="Canada","unknown,Canada"),
response=replace(response,str_detect(response,"Dominica"),"unknown,Dominican Republic"),
response=replace(response,str_detect(response,"Puerto"),"unknown,Puerto Rico")) %>%
separate(response, c("town", "state"), sep=",", remove=FALSE, extra="merge")
#Trim white space
geo$state <- trimws(geo$state, which="both")
#Code geography data
geo <- geo %>%
mutate(state_recode=state,
state_recode=replace(state_recode,state=="PA","Pennsylvania"),
state_recode=replace(state_recode,state=="Pa","Pennsylvania"),
state_recode=replace(state_recode,state=="NY","New York"))
#Reshape data
geo_reshape <- geo %>%
select(ID, cat_code, town, state_recode) %>%
group_by(ID) %>%
unite(place, town, state_recode, sep=", ") %>%
spread(cat_code, place)
View(geo)
rm(summary_back, mood, handed, handed_score, geo, geo_reshape)
View(attitude)
View(background)
View(attitude)
#Create new dataframe for clean data
summary_back <- background %>% select(ID)
background %>% filter(is.na(everything()))
#Check race, ethnicity, and gender data
background %>% filter(is.na(Race) | is.na(Ethnicity) | is.na(Gender))
background %>% filter_all(any_vars(is.na()))
background %>% filter_all(is.na(any_vars()))
background %>% filter_all(all_vars(), is.na())
background %>% filter_all(all_vars(is.na()))
background %>% filter_all(all_vars(is.na(.)))
background %>% filter_all(all_vars(is.na(.)))
background %>% filter_all(any_vars(is.na(.)))
background %>% filter_all(any_vars(is.na(.)))
background %>% filter_at(any_vars(is.na(.)))
#Recode missing data
summary_back <-
x <- background %>%
select(ID, Race, Ethnicity, Gender) %>%
replace(is.na(.), "unknown")
x <- background %>%
select(ID, Race, Ethnicity, Gender) %>%
replace(is.na(.), "unknown")
View(x)
rm(x)
View(background)
x <- background %>%
select(Race, Ethnicity, Gender) %>%
replace(is.na(.), "unknown")
# Install packages
install.packages(c("SemNetDictionaries", "SemNetCleaner",
"SemNeT", "NetworkToolbox"))
# Load packages
library(SemNetDictionaries)
library(SemNetCleaner)
library(SemNeT)
library(NetworkToolbox)
# Documentation for `textcleaner` function
?textcleaner
# Run 'textcleaner'
clean <- textcleaner(data = open.animals[,-c(1:2)], miss = 99,
partBY = "row", dictionary = "animals")
rm(clean)
clean <- textcleaner(data = open.animals[,-c(1:2)], miss = 99,
partBY = "row", dictionary = "animals")
?loadNamespace
# Load packages
library(SemNetDictionaries)
library(SemNetCleaner)
library(SemNeT)
library(NetworkToolbox)
# Append 'animals.dictionary'
append.dictionary(animals.dictionary,
"tasselled wobbegong",
save.location = "choose")
?XQuartz
#R setup
chooseCRANmirror(graphics=FALSE, ind=1)
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
#Load global variables
my_dir <- "/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/r_scripts"
#Load ERP plots
n <- "MAE"
source(paste(my_dir,"DM_plots.R",sep="/"), local=TRUE)
#Load attitude, background, SUSE variables, dialect, and judgment data
n <- "Behavior"
code_geo <- FALSE
new_image <- FALSE
source(paste(my_dir,"DM_attitudes_survey.R",sep="/"), local=TRUE)
#Set directory back to poster
setwd("/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/poster/Psychonomics_html")
#Create scale variables
scale_mean_5 <- mean(c(1,5))
scale_mean_4 <- mean(c(1,4))
#Create subset of dataframe and set factor levels
MAE_mean_multi <- mean_multi %>%
dplyr::filter(ID %notin% SUSE_id$ID) %>%
gather(type, rating, -ID) %>%
separate(type,c("modal","measure"),sep="_",remove=FALSE) %>%
mutate(modal=factor(modal,
levels=c("standard","double","incorrect"),
labels=c("Standard single modal", "Attested double modal", "Unattested double modal")),
measure=factor(measure,
levels=c("acceptable","understand","familiar"),
labels=c("Acceptability","Intelligibility","Familiarity")))
#Create table with confidence intervals
library(Rmisc)
MAE_multi_error <- summarySE(MAE_mean_multi, measurevar="rating", groupvars=c("modal","measure"))
detach("package:Rmisc", unload=TRUE)
MAE_multi_error <- MAE_multi_error %>% mutate(scale=rep(c(scale_mean_5,scale_mean_5,scale_mean_4),3),
max=rep(c(5,5,4),3))
#Create plot
ggplot(MAE_multi_error, aes(modal, rating, fill=modal)) +
geom_bar(position="dodge", stat="identity") +
geom_errorbar(aes(ymin=rating-ci, ymax=rating+ci), width=0.1) +
scale_y_continuous(expand=c(0,0),limits=c(0,5)) +
coord_cartesian(ylim=c(1,5.01)) +
scale_x_discrete(expand=c(0,0)) +
theme_classic() +
facet_wrap(~measure, strip.position="bottom") +
scale_fill_manual(values=c(sm_shade,dm_shade,psu_grey),
name="Modal type") +
geom_hline(aes(yintercept=scale,linetype="Scale mean")) +
geom_hline(aes(yintercept=max,linetype="Scale maximum")) +
scale_linetype_manual(name="Scale type",
values=c("solid","dashed"),
labels=c("Scale maximum","Scale mean")) +
theme(text=element_text(family="Avenir"),
axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank(),
strip.background=element_blank()) +
ylab("Mean ratings")
#Create scale variables
scale_mean_5 <- mean(c(1,5))
scale_mean_4 <- mean(c(1,4))
#Create subset of dataframe and set factor levels
MAE_mean_multi <- mean_multi %>%
dplyr::filter(ID %notin% SUSE_id$ID) %>%
gather(type, rating, -ID) %>%
separate(type,c("modal","measure"),sep="_",remove=FALSE) %>%
mutate(modal=factor(modal,
levels=c("standard","double","incorrect"),
labels=c("Standard single modal", "Attested double modal", "Unattested double modal")),
measure=factor(measure,
levels=c("acceptable","understand","familiar"),
labels=c("Acceptability","Intelligibility","Familiarity")))
#Create table with confidence intervals
library(Rmisc)
MAE_multi_error <- summarySE(MAE_mean_multi, measurevar="rating", groupvars=c("modal","measure"))
detach("package:Rmisc", unload=TRUE)
MAE_multi_error <- MAE_multi_error %>% mutate(scale=rep(c(scale_mean_5,scale_mean_5,scale_mean_4),3),
max=rep(c(5,5,4),3))
#Create plot
ggplot(MAE_multi_error, aes(modal, rating, fill=modal)) +
geom_bar(position="dodge", stat="identity") +
geom_errorbar(aes(ymin=rating-ci, ymax=rating+ci), width=0.1) +
scale_y_continuous(expand=c(0,0),limits=c(0,5)) +
coord_cartesian(ylim=c(1,5.01)) +
scale_x_discrete(expand=c(0,0)) +
theme_classic() +
facet_wrap(~measure, strip.position="bottom") +
scale_fill_manual(values=c(sm_shade,dm_shade,psu_grey),
name="Modal type") +
geom_hline(aes(yintercept=scale,linetype="Scale mean")) +
geom_hline(aes(yintercept=max,linetype="Scale maximum")) +
scale_linetype_manual(name="Scale type",
values=c("solid","dashed"),
labels=c("Scale maximum","Scale mean")) +
theme(text=element_text(family="Avenir"),
axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank(),
strip.background=element_blank()) +
ylab("Mean ratings")
#R setup
chooseCRANmirror(graphics=FALSE, ind=1)
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
#Load global variables
my_dir <- "/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/r_scripts"
#Load ERP plots
n <- "MAE"
source(paste(my_dir,"DM_plots.R",sep="/"), local=TRUE)
#Load attitude, background, SUSE variables, dialect, and judgment data
n <- "Behavior"
code_geo <- FALSE
new_image <- FALSE
source(paste(my_dir,"DM_attitudes_survey.R",sep="/"), local=TRUE)
#Set directory back to poster
setwd("/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/poster/Psychonomics_html")
library(magick)
setwd("/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/poster/Psychonomics")
pagedown::chrome_print("file://localhost/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/poster/Psychonomics_poster/Psychonomics.html")
setwd("/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/poster/Psychonomics_poster")
pagedown::chrome_print("file://localhost/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/poster/Psychonomics_poster/Psychonomics.html")
setwd("/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/poster/Psychonomics_poster")
pagedown::chrome_print("file://localhost/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/poster/Psychonomics_poster/Psychonomics.html")
setwd("/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/poster/Psychonomics_poster")
pagedown::chrome_print("file://localhost/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/poster/Psychonomics_poster/Psychonomics.html")
#R setup
chooseCRANmirror(graphics=FALSE, ind=1)
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
#Load global variables
top_level <- "/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/"
my_dir <- paste0(top_level, "r_scripts")
#Load ERP plots
n <- "MAE"
source(paste(my_dir,"DM_plots.R",sep="/"), local=TRUE)
#Load attitude, background, SUSE variables, dialect, and judgment data
n <- "Behavior"
code_geo <- FALSE
new_image <- FALSE
source(paste(my_dir,"DM_attitudes_survey.R",sep="/"), local=TRUE)
#Restrict behavioral data to correct group
summary_MAE <- summary_back %>%
dplyr::filter(ID %notin% SUSE_id$ID & ID %notin% "214")
#Create variables for graphs
scale_mean_5 <- mean(c(1,5))
scale_mean_4 <- mean(c(1,4))
text_size <- 12
theme_specs <- list(theme(text=element_text(family="Avenir"),
axis.title.x=element_blank(),
axis.ticks.x=element_blank(),
strip.background=element_blank(),
legend.key.size=unit(0.4, "cm"),
plot.title=element_text(size=text_size),
axis.title.y=element_text(size=text_size*0.75)))
#Sentence strings
critical_dm_ex <- "\"She thinks she *might **should*** ask the professor for an extension.\""
critical_sm_ex <- "\"She thinks she ***should*** ask the professor for an extension.\""
critical_un_ex <- "\"She thinks she *could **should*** ask the professor for an extension.\""
critical_context <- "\"Kaitlyn is having a hard time with her essay.\""
filler_context <- "\"Kaitlyn waits for the bus every morning to go to work.\""
filler_ex <- "\"She said *the that* bus is usually late.\""
dm_predict <- "(N400-)P600"
sm_predict <- "Baseline"
un_predict <- "Not applicable"
fill_predict <- "Not analyzed"
off_predict <- "Pattern together"
#Stimulus table
headers <- c("Condition","Context sentence","Type","Experimental sentence","ERP prediction","Offline prediction")
critical_dm <- c("Critical",critical_context,"Attested double modal",critical_dm_ex,dm_predict,off_predict)
critical_sm <- c("Critical",critical_context,"Standard single modal",critical_sm_ex,sm_predict,sm_predict)
critical_un <- c("Critical",critical_context,"Unattested double modal",critical_un_ex,un_predict,off_predict)
filler <- c("Filler",filler_context,"",filler_ex,fill_predict,un_predict)
stim_table <- rbind(critical_sm, critical_dm, critical_un, filler)
rownames(stim_table) <- NULL
colnames(stim_table) <- headers
#Knit table
knitr::kable(stim_table) %>%
kableExtra::kable_styling(font_size=35) %>%
collapse_rows(columns = 1:6, valign = "middle") %>%
row_spec(4, extra_css="border-top: 5px solid #d7d8db; border-bottom: 5px solid #d7d8db") %>%
row_spec(3, extra_css="border-top: 5px solid #d7d8db") %>%
footnote(general="ERP time-locked to second modal (could or should) in double modal sentences to compare to standard single modal",
general_title="")
#Participant table
cutoff <- "Exposure and familiarity"
cutoff_SUSE <- "\u2265 either scale mean"
cutoff_MAE <- "< both scale means"
headers <- c("Group", cutoff, "Stage", "Results presented", "Total", "Geography", "ERP", "Offline")
MAE_line <- c("MAE", cutoff_MAE, "Complete", "All", "32", "30", "27", "29")
SUSE_line <- c("SUSE", cutoff_SUSE, "Ongoing", "Geography", "10", "9", "", "")
stim_table <- rbind(MAE_line, SUSE_line)
rownames(stim_table) <- NULL
colnames(stim_table) <- headers
#Knit table
knitr::kable(stim_table) %>%
kableExtra::kable_styling(font_size=35) %>%
row_spec(1, background=paste0(sm_shade,"20")) %>%
row_spec(2, background=paste0(dm_shade,"20"))
library(magick)
#Load map image and trim white space
file_name <- paste0(top_level, "/posters/Psychonomics_poster/images/dialect_map_caption.png")
dialect_map <- image_read(file_name)
dialect_map <- image_trim(dialect_map)
dialect_map
library(patchwork)
(buffer_plot / lf_plot / lp_plot / theme_plot) + plot_layout(heights = c(1,2,2,1)) |
(fz_plot / cz_plot / pz_plot) |
(buffer_plot / rf_plot / rp_plot / legend_plot) + plot_layout(heights = c(1,2,2,1))
#Create subset of dataframe and set factor levels
exposure <- summary_MAE %>%
select(ID, MC_mean, say_mean, hear_mean, south_only, hear_only, say_only) %>%
gather(type, rating, -ID) %>%
mutate(group=ifelse(str_detect(type,"only"),"Southern features","Double modals"),
type=ifelse(str_detect(type,"hear"),"Comprehension",
ifelse(str_detect(type,"say"),"Production","Overall")),
type=factor(type,
levels=c("Overall","Comprehension","Production"),
labels=c("Overall exposure","Comprehension","Production")))
#Create table with confidence intervals
library(Rmisc)
exposure_error <- summarySE(exposure, measurevar="rating", groupvars=c("group","type"))
#Create plot
ggplot(exposure_error, aes(group, rating, fill=group)) +
geom_bar(position="dodge", stat="identity") +
geom_errorbar(aes(ymin=rating-ci, ymax=rating+ci), width=0.1) +
facet_wrap(~type, strip.position="bottom") +
scale_y_continuous(expand=c(0,0), limits=c(0,3), breaks=c(1,2,3)) +
coord_cartesian(ylim=c(1,3.01)) +
scale_x_discrete(expand=c(0,0)) +
geom_hline(aes(yintercept=scale_mean_5,linetype="Scale mean")) +
theme_classic() +
scale_fill_manual(values=c(dm_shade,paste0(dm_shade,"50")),
name="Exposure type") +
labs(title="Exposure to double modals compared to other Southern dialect features") +
scale_linetype_manual(name="Scale type",
values="dashed",
labels="Scale mean") +
labs(caption="Southern dialect exposure means do not include exposure to double modals") +
guides(fill=guide_legend(order=1),
linetype=guide_legend(order=2)) +
theme_specs +
theme(axis.text.x=element_blank()) +
ylab("Mean rating (by participant)")
#Create subset of dataframe and set factor levels
MAE_mean_multi <- summary_MAE %>%
select(ID, contains("double"), contains("incorrect"), contains("standard")) %>%
gather(type, rating, -ID) %>%
separate(type,c("modal","measure"),sep="_",remove=FALSE) %>%
mutate(modal=factor(modal,
levels=c("standard","double","incorrect"),
labels=c("Standard single modal", "Attested double modal", "Unattested double modal")),
measure=factor(measure,
levels=c("acceptable","understand","familiar"),
labels=c("Acceptability","Intelligibility","Familiarity"))) %>%
drop_na()
#Create table with confidence intervals
library(Rmisc)
MAE_multi_error <- summarySE(MAE_mean_multi, measurevar="rating", groupvars=c("modal","measure"))
MAE_multi_error <- MAE_multi_error %>%
mutate(scale=rep(c(scale_mean_5,scale_mean_5,scale_mean_4),3),
max=rep(c(5,5,4),3))
#Create plot
ggplot(MAE_multi_error, aes(modal, rating, fill=modal)) +
geom_bar(position="dodge", stat="identity") +
geom_errorbar(aes(ymin=rating-ci, ymax=rating+ci), width=0.1) +
scale_y_continuous(expand=c(0,0),limits=c(0,5)) +
coord_cartesian(ylim=c(1,5.01)) +
scale_x_discrete(expand=c(0,0)) +
theme_classic() +
facet_wrap(~measure, strip.position="bottom") +
scale_fill_manual(values=c(sm_shade,dm_shade,psu_grey),
name="Modal type") +
geom_hline(aes(yintercept=scale,linetype="Scale mean")) +
geom_hline(aes(yintercept=max,linetype="Scale maximum")) +
scale_linetype_manual(name="Scale type",
values=c("solid","dashed"),
labels=c("Scale maximum","Scale mean")) +
labs(title="Ratings of experimental sentence stimuli") +
theme_specs +
theme(axis.text.x=element_blank()) +
ylab("Mean rating (by participant)")
#Pull values for correlation matrix
south_dat <- summary_MAE %>%
select(double_acceptable, double_familiar, double_understand, South, MC_mean, south_only)
#Create correlation matrix and separate coefficients from p values
south_matrix <- rcorr(as.matrix(south_dat),type="pearson")
south_r <- as.data.frame(south_matrix$r)
south_p <- as.data.frame(south_matrix$P)
cor_vals_row <- colnames(south_r)
cor_vals_col <- colnames(south_r)
cor_len <- length(cor_vals_row)
#Rename rows and columns in lists
for (i in 1:cor_len) {
#Edit lists of names
cor_vals_row[i] <- paste(cor_vals_row[i], "_row", sep="")
cor_vals_col[i] <- paste(cor_vals_col[i], "_col", sep="")
}
#Rename columns
colnames(south_r) <- cor_vals_col
colnames(south_p) <- cor_vals_col
#Change row and column names in order to gather
south_r <- tibble::rowid_to_column(south_r, "row_key") %>%
mutate(row_key=cor_vals_row)
south_p <- tibble::rowid_to_column(south_p, "row_key") %>%
mutate(row_key=cor_vals_row)
#Gather into long format
south_r <- south_r %>%
gather(col_key, coef, -row_key)
south_p <- south_p %>%
gather(col_key, p_val, -row_key)
#Combine coeffients and p values
south_matrix <- full_join(south_r, south_p) %>%
mutate(p_val=replace_na(p_val,1))
#Create columns for final table
south_matrix <- south_matrix %>%
mutate(p_label=ifelse(p_val <= 0.001, "***",
ifelse(p_val <= 0.01, "**",
ifelse(p_val <= 0.05, "*", ""))),
coef_label=as.character(format(coef,digits=1,nsmall=1)),
table_val=paste(coef_label, p_label, sep=""),
table_val=ifelse(table_val==" 1.00","1",table_val))
#Reformat table for printing
south_table <- south_matrix %>%
select(row_key, col_key, table_val) %>%
spread(col_key, table_val) %>%
select(row_key, double_acceptable_col, double_familiar_col, double_understand_col,
MC_mean_col, south_only_col, South_col)
#Rename rows and columns
var_names <- c("Acceptability", "Familiarity", "Intelligibility", "Exposure (DM)",
"Exposure (SUSE)", "Culture")
colnames(south_table) <- c("Variables", var_names)
south_table <- south_table %>%
mutate(Variables=var_names)
#Remove unnecessary variables
rm(var_names, south_matrix, south_p, south_r, cor_vals_row, cor_vals_col, cor_len, south_dat)
#Create table
knitr::kable(south_table) %>%
kableExtra::kable_styling(full_width=TRUE, font_size=30) %>%
row_spec(6, extra_css="border-bottom: 5px solid #d7d8db") %>%
add_header_above(header=c("Pairwise Pearson correlation matrix"=7), align="l") %>%
footnote(general="All pairwise correlations with centro-parietal P600 amplitude and language attitudes n.s. at *p* < .05 level",
general_title="", footnote_as_chunk=TRUE)
#Create scale variables
sm_scale <- 1
dm_scale <- 2
#Get paraphrase rates
paraphrase_labels <- paraphrase %>%
dplyr::filter(ID %notin% SUSE_id$ID & ID %notin% "214")
paraphrase_total <- nrow(paraphrase_labels)
paraphrase_labels <- paraphrase_labels %>%
dplyr::filter(response_score > 0)
paraphrase_actual <- nrow(paraphrase_labels)
paraphrase_rate <- paraphrase_actual/paraphrase_total
#Create subset of dataframe and set factor levels
MAE_paraphrase <- paraphrase %>%
dplyr::filter(ID %notin% SUSE_id$ID & ID %notin% "214" & response_score > 0) %>%
select(ID, modal, condition, epist_score, root_score, response_score) %>%
gather(key, score, -c(ID, modal, condition)) %>%
mutate(modal=factor(modal,
levels=c("could","should"),
labels=c("Could", "Should")),
condition=factor(condition,
levels=c("standard","double","incorrect"),
labels=c("Standard single modal", "Attested double modal", "Unattested double modal")),
key=factor(key,
levels=c("response_score", "epist_score", "root_score"),
labels=c("Overall meaning", "Epistemic meaning", "Root meaning")))
#Create table with confidence intervals
library(Rmisc)
MAE_paraphrase_error <- summarySE(MAE_paraphrase, measurevar="score", groupvars=c("modal","condition","key"))
MAE_paraphrase_error <- MAE_paraphrase_error %>%
arrange(key) %>%
mutate(line_1=c(rep(dm_scale,6), rep(NA,12)),
line_2=c(rep(sm_scale,6), rep(NA,12)),
line_3=c(rep(NA,6), rep(sm_scale,12)),
y_max=c(rep(2.01,6), rep(1.005,12)),
y_min=c(rep(0,18)),
proportion=paste0(as.character(round((N/paraphrase_actual)*100,1)),"%"))
#Create plot
ggplot(MAE_paraphrase_error, aes(modal, score,
ymin=score-ci, ymax=score+ci,
fill=condition)) +
geom_bar(position="dodge", stat="identity") +
geom_errorbar(width=0.2, position=position_dodge(width=0.9)) +
scale_y_continuous(expand=c(0,0), breaks=pretty_breaks()) +
scale_x_discrete(expand=c(0,0)) +
theme_classic() +
facet_wrap(~key, strip.position="bottom", scales="free_y") +
geom_hline(aes(yintercept=line_3,linetype="Standard single modals")) +
geom_hline(aes(yintercept=line_1,linetype="Attested double modals")) +
geom_hline(aes(yintercept=line_2,linetype="Individual modals")) +
geom_blank(aes(y=y_min)) +
geom_blank(aes(y=y_max)) +
scale_fill_manual(values=c(sm_shade,dm_shade,psu_grey),
name="Modal type") +
scale_linetype_manual(name="Score expectation",
values=c("solid","dashed","dotted"),
labels=c("Attested double modals",
"Standard single modals",
"Individual modals")) +
labs(title="Paraphrases of experimental sentence stimuli",
caption="Epistemic modals express subjective impressions of truth or likelihood (might) \nRoot modals express possibility, permission, necessity, or obligation (could/should)") +
theme_specs +
guides(fill=guide_legend(order=1),
linetype=guide_legend(order=2)) +
ylab("Mean paraphrase score (across participants)")
# geom_text(aes(label=proportion), position=position_dodge(width=0.9))
setwd("/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/posters/Psychonomics_poster")
path <- "file://localhost/Users/hollyzaharchuk/Mirror/DM_analysis_scripts/posters/Psychonomics_poster/"
file <- paste0(path, "Psychonomics.html")
pagedown::chrome_print(file)
